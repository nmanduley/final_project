{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data paths\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dirs\n",
    "# os.makedirs(POS_PATH)\n",
    "# os.makedirs(NEG_PATH)\n",
    "# os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncompress LFW database\n",
    "# # Download dataset from http://vis-www.cs.umass.edu/lfw/#download\n",
    "# # Into /facial_recognition folder\n",
    "# filename = 'lfw.tgz'\n",
    "# !tar -xf filename   # Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Put all the LFW data into the negative folder\n",
    "# for directory in os.listdir('lfw'):\n",
    "#     for file in os.listdir(os.path.join('lfw', directory)):\n",
    "#         EX_PATH = os.path.join('lfw', directory, file)\n",
    "#         NEW_PATH = os.path.join(NEG_PATH, file)\n",
    "#         os.replace(EX_PATH, NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import uuid to generate unique identifier\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Cut frame to 250x250p\n",
    "    dim = 250\n",
    "    x_offset = 250\n",
    "    y_offset = 150\n",
    "    frame = frame[y_offset:y_offset+dim, x_offset:x_offset+dim, :]\n",
    "\n",
    "    # Collect anchors\n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        img_name = os.path.join(ANC_PATH, f'{uuid.uuid1()}.jpg')\n",
    "        cv2.imwrite(img_name, frame)\n",
    "\n",
    "    # Collect positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        img_name = os.path.join(POS_PATH, f'{uuid.uuid1()}.jpg')\n",
    "        cv2.imwrite(img_name, frame)\n",
    "\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get directories\n",
    "anchor = tf.data.Dataset.list_files(ANC_PATH + os.sep + '*.jpg').take(300)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH + os.sep + '*.jpg').take(300)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH + os.sep + '*.jpg').take(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and resize\n",
    "def preprocess_image(file_path):\n",
    "    \"\"\"Receives a path to an img and returns a 100x100p normalized image\"\"\"\n",
    "    # Read image\n",
    "    raw_img = tf.io.read_file(file_path)\n",
    "\n",
    "    # Load image\n",
    "    img = tf.io.decode_jpeg(raw_img)\n",
    "\n",
    "    # Preprocessing\n",
    "    img = tf.image.resize(img, (100,100))\n",
    "    \n",
    "    # Normalizing\n",
    "    img = img/255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcatenateDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create labeled dataset\n",
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build train and test partition\n",
    "def preprocess_twin(input_img, validation_img, label) -> tuple:\n",
    "    '''Receives input and validation image with the corresponding label and returns\n",
    "    a tuple containing the preprocessed input and validation image, as well as the label'''\n",
    "    return (preprocess_image(input_img), preprocess_image(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'data\\\\anchor\\\\1f55f181-856b-11ed-8068-34e6adf636cc.jpg', b'data\\\\positive\\\\412c0753-856b-11ed-b3b0-34e6adf636cc.jpg', 1.0)\n"
     ]
    }
   ],
   "source": [
    "example = samples.next()\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = preprocess_twin(*example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataloader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training partition\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*0.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3c6c0ed584c41c6a98692036edee3a9ae75e8fb1758ae731ddbeee0007edfe1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
